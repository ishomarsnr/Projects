<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="Phishing Website Detection Using Machine Learning" />
    <meta name="author" content="Ishmael Omar Mohammed" />
    <title>Phishing Website Detection Using Machine Learning</title>
    <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
    <!-- Font Awesome icons (free version)-->
    <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
    <!-- Google fonts-->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="css/styles.css" rel="stylesheet" />
</head>
<body id="page-top">
    <div class="container-fluid p-0">
        <!-- Content-->
        <section class="resume-section" id="about">
            <div class="resume-section-content">
                <h1 class="mb-0">
                    Phishing Website Detection
                    <span class="text-primary">Using Machine Learning</span>
                </h1>
                <h2>Introduction</h2>
                <p class="lead mb-5">
                    Phishing attacks involve deceptive websites and emails that mimic legitimate entities to steal sensitive information from users. These attacks are among the most common cybersecurity threats faced today. Machine learning offers powerful tools to automatically detect and flag these threats by learning from patterns in data. In this project, I apply three different machine learning models to a dataset of websites, aiming to classify them as either phishing or legitimate.
                </p>
                <h2>Dataset Description</h2>
                <p class="lead mb-5">
                    The dataset used in this analysis comprises various features of websites, including URL length, the use of HTTPS, the presence of an IP address in the URL, etc. It contains 10,000 entries, each labeled as '0' (legitimate) or '1' (phishing). This data was sourced from <a href="https://www.kaggle.com/datasets/shibumohapatra/book-my-show?resource=download" target="_blank">Kaggle</a>, which compiled it to facilitate machine learning applications in cybersecurity.
                </p>
                <h2>Summary of Findings</h2>
                <p class="lead mb-5">
                    I evaluated three machine learning models: Logistic Regression, Random Forest, and Support Vector Machine. The goal was to determine which model provides the highest accuracy using parameter tuning and cross-validation techniques. The findings are summarized at the end of this project.
                </p>
                <pre><code>
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score

# Load and preprocess data
data_path = 'dataset.csv'
data = pd.read_csv(data_path)

# Convert all columns to numeric, coercing errors to NaN
for col in data.columns:
    data[col] = pd.to_numeric(data[col], errors='coerce')

# Handle NaN values by forward filling
data.fillna(method='ffill', inplace=True)

# Split the dataset
X = data.drop('Result', axis=1)
y = data['Result']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test_scaled)
                </code></pre>
                <h2>Model Setup and Evaluation</h2>
                <pre><code>
# Setup dictionary of models
models_params = {
    'Logistic Regression': {
        'model': LogisticRegression(max_iter=1000),
        'params': {'C': [0.1, 1, 10], 'penalty': ['l2']}
    },
    'Random Forest': {
        'model': RandomForestClassifier(),
        'params': {'n_estimators': [50, 100], 'max_features': ['sqrt']}
    },
    'Support Vector Machine': {
        'model': SVC(),
        'params': {'C': [1], 'kernel': ['linear']}
    }
}

# Apply GridSearchCV and evaluate models
results = []
for model_name, mp in models_params.items():
    clf = GridSearchCV(mp['model'], mp['params'], cv=5, scoring='accuracy', return_train_score=False)
    clf.fit(X_train_scaled, y_train)
    results.append({
        'model': model_name,
        'best_score': clf.best_score_,
        'best_params': clf.best_params_
    })

# Print results
for result in results:
    print(result['model'])
    print('Best Score:', result['best_score'])
    print('Best Parameters:', result['best_params'])
                </code></pre>
                <h2>Conclusion and Recommendations</h2>
                <p class="lead mb-5">
                    The Random Forest model outperformed others with an accuracy of approximately 96.8%, which implies that it could be the most suitable model for this particular dataset, likely due to its ability to handle nonlinear relationships and interactions between features effectively. Logistic Regression and SVM show competitive performance, but both are slightly lower than Random Forest.
                </p>
            </div>
        </section>
    </div>
    <!-- Bootstrap core JS-->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Core theme JS-->
    <script src="js/scripts.js"></script>
</body>
</html>
